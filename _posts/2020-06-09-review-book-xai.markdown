---  
layout: post  
title: "[리뷰] XAI 설명 가능한 인공지능 (인공지능을 해부하다)"  
subtitle: "블랙박스를 이해하고 시스템의 신뢰성을 높이기 위한"  
categories: review  
tags: review book xai explainable artificial intelligence pfi pdp lime shap filter visualization lrp
comments: true  
header-img: img/review/2020-06-05-review-book-xai-1.png
---  
  
> `위키북스` 출판사의 `"XAI 설명 가능한 인공지능, 인공지능을 해부하다(안재현 저)"`를 읽고 작성한 리뷰입니다.  

![표지](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-1.png)  

---

* __XAI(eXplainable Artificial Intelligence, 설명 가능한 인공지능)__  
  > XAI는 말 그대로 설명 가능한 인공지능을 의미한다. 
  
  딥러닝은 성능이 훌륭한 만큼이나 해석력이 떨어지기에 내부가 `블랙박스`로 표현되곤 한다. 1975년 Buchanan과 Shortliffe의 논문에서 설명 가능한 의사 결정 체계라는 의미로 처음 사용된 후, 2004년이 되어서야 Fisher, Rudin, Dominic에 의해 현재 의미를 뜻하는 전문 용어로 자리잡았다.  
  
  AI는 인간의 뇌를 모방하여 탄생하였다. XAI는 거꾸로 AI의 뇌(?)를 Hacking하는 과정으로 볼 수 있겠다. 양자 간 끊임없는 Hacking 속에 우리는 인간의 지능과 인공의 지능을 더욱 잘 이해할 수 있게 될 것이므로 XAI의 중요성은 두말할 나위 없다.

  미국의 국가 주도 첨단 기술 연구는 보통 NASA(미국 항공우주국 제트추진 연구소)와 `DARPA(방위 고등 연구 계획국)`가 이끄는데, 두 기관 중 하나인 DARPA의 인공지능 관련 프로젝트이기도 하다. DARPA의 지침에 따르면 XAI는 다음 3가지 과정을 따른다.

  + 1.기존 머신러닝 모델에 설명 가능한 기능 추가
  + 2.머신러닝 모델에 HCI(Human Computer Interaction) 기능 추가
  + 3.XAI를 통한 현재 상황의 개선

  최근 네이버 리서치 헤드 하정우님의 인터뷰 기사 - [OCR은 한국이 세계 최고, '설명 AI'에 승부 걸어야](https://m.news.naver.com/read.nhn?mode=LSD&mid=sec&sid1=105&oid=092&aid=0002188379&fbclid=IwAR3I1WRtx19g-frQngQOzNInv4CJINFzToxyBEaUl-kqwltpmdGiqtN4DKs) - 에서도 XAI와 HCI의 중요성을 확인할 수 있다. AI 기술이 생활속에 녹아들고 소비자가 사용하기 위해서는 XAI가 선결 과제임과 동시에 우리나라가 AI 강국으로 발돋움하기 위한 기술임을 강조한다.

  본 리뷰에서는 먼저 본 도서의 매력에 대해 소개한 후, `다양한 XAI 기법`들을 소개하고자 한다. 배운 기술을 모두 정리해놓고 싶은 것이 쟁이의 욕심이지만 그렇게 되면 리뷰가 리뷰가 아니게 되므로, 각 기법의 의미, 활용법, 시각화 자료 위주로 소개하고자 한다.

---

* __본 도서의 매력__  
  본 도서에는 두가지의 매력이 있다. 하나는 `XAI를 다룬 국내 최초 서적`이라는 점이다. 본 글을 작성하는 현시점에도 국내 유일한 서적임을 확인했다. 다른 하나는 XAI라는 어려운 기술을 독자들에게 `쉽게 전달`한다는 점이다. 

  + 생활과 밀접한 `쉬운 AI 예제`를 선택한다. 
    - 집값예측, 신용대출, 얼굴 사진 감정 분석 등
    - 쉬운 예제 덕분에 XAI의 핵심에 집중할 수 있다.

  + AI 모델의 구현 및 `성능 고도화 과정을 분리`하여 다룬다. 
    - 개선이 필요한 AI모델의 핵심을 심플하게 이해할 수 있다.
    - 예제 모델이 한번에 이해되지 않더라도 고도화를 통해 반복 학습이 가능하다.
    - 모델 자체의 성능 향상에 대한 기법도 덤으로 배울 수 있다.

  + `가독성`이 매우 뛰어나다. 
    - XAI외 부수적인 선수 지식들에 대한 설명을 모두 다룬다.
    - 핵심만 간결히 전달하여 이해의 흐름이 쉽게 끊기지 않는다.

  + 마무리 디테일이 강점이다.
    - 각 단원마다 다양한 XAI 기술을 접하면 머리속에 한바탕 폭풍우가 휩쓴 느낌이 된다.
    - 그로 인해 독자가 현 좌표를 잃기 쉬운데 단원마다 마무리 설명이 체계적으로 되어있어 현 위치를 파악할 수 있다. (예:150p)
    - 8, 9장에서 앞서 배운 XAI 기법들을 총망라하여 실전에 적용한다.
    - 이 과정에서 반감된 기억을 다시 언급하여 흡수할 수 있도록 이끌어 준다.

  읽는 내내 저자 내공의 깊이에 감탄하기도 했고, 딥러닝의 뇌(?)를 해킹하는 즐거움도 있었지만 이에 못지 않게 위에서 언급한 짜임새 있는 구성에 놀랐다. 독자가 지쳐 포기할 때를 정확히 알고 있는 느낌이었고, 그때마다 저자의 묘한 티칭 기술로 구제받을 수 있었다. 
  
  추측컨데 본 도서의 짜임새는 아마 저자의 학습 방식과도 닮아있지 않나 생각한다. `체계화되어 핵심을 찌르는 짜임새` 덕분에 어려운 최신 기술을 편하게 얻을 수 있어 대만족이었다.

  본 도서를 읽고나면 `XAI라는 최신기술, 현재까지의 연구성과, 블랙박스의 해석은 물론 현재 모델의 개선 방법까지` 많은 것들을 얻을 수 있다. 아는 만큼만 보인다고 나의 경우엔 학식이 얕아 기법들을 완벽히 이해하진 못했지만 2가지는 확실하게 얻을 수 있었다. 
  
  하나는 `Data Analysis에 있어 차원이 다른 분석 기법`을 얻었다는 점, 또 다른 하나는 `모델의 성능이 떨어질 경우 활용할 수 있는 일종의 디버깅과 유사한 기법`을 얻었다는 점이다. 
  
  XAI 자체에 관심이 없는 분일지라도 모델의 성능을 높이는데 있어 자유로운 분들이 얼마나 될까? 그런점에서 본 도서는 AI를 다루는 모든 분들께 도움이 될 것이다. 
  
  이어서 개인적으로 학습한 `XAI 기법 7가지`를 아래와 같이 정리해 본다.

---

* __기법1 - `피처 중요도`(Feature Importance, Permutation Importance)__  
  - 모델의 피처 중 어느 피처가 가장 중요한지 나타내는 기법이다.
  - 특정 피처의 값을 임의의 값으로 치환했을 때 원본보다 에러가 얼마나 더 커지는지를 판단하여 중요도를 측정한다.  
  - 단, 음양의 방향이 없고, scale에 따라 모델에 미치는 영향 파악이 어려우며, 피처 간 의존성 존재 시 신뢰할 수 없다.
  - 아래 그림은 파마 인디언 당뇨병 결정 모델에서 트리 깊이가 3일때 가장 중요한 피처가 글루코스(Glucose, 포도당 농도)임을 보여준다.
  ![피처 중요도](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-5.png)

---

* __기법2 - `부분 의존성 플롯`(PDP, Partial Dependence Plots)__   
  - 피처가 모델에 미치는 영향을 판단하는 기법이다.
  - 특정 피처의 값을 선형적으로 변경하면서 알고리즘 해석 능력이 얼마나 증가하고 감소하는지를 관찰한다.
  - 피처 중요도가 가진 단점을 상당수 보완하지만 계산이 오래걸리는 단점이 있다.
  - 아래 그림은 파마 인디언 당뇨병 결정 모델에서 혈압 피처의 증감에 따른 당뇨병 발병 관계를 보여준다. 
  ![PDP](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-3.png)
  - 파이썬의 pdpbox를 활용하여 위 그림 외에도 그린 목표 플롯, 예측에 대한 의존성 플롯, 두 피처 간 의존성 플롯, 피처간 부분 의존성 등고선 비교 등이 가능하다.

---

* __기법3 - `글로벌 대리 분석`(Global Surrogate)__   
  - 블랙박스 모델과 유사한 기능을 흉내내는 설명 가능한 모델 여러개를 대리로 만들어 원본 블랙박스 모델을 분석하는 기법이다.
  - 아래 그림은 유사 모델로 사용할 수 있는 잘 알려진 XAI 알고리즘의 특징을 정리한 표이다. 
  ![GS](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-6.png)
  

---

* __기법4 - `로컬 대리 분석`(LIME, Local Interpretable Model-agnostic Explanations)__   
  - 데이터 하나에 초점을 맞추어 블랙박스가 해석하는 과정을 분석하는 기법이다.
  - 첫번째 그림은 슈퍼픽셀을 변형해가며 모델이 가장 영향을 많이 받는 `슈퍼픽셀`을 찾는 과정이다.
    ![LIME1](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-7.png)
    + 슈퍼픽셀이란, 특정 이미지의 관심 영역(노란색 선)을 주변으로 영역을 확대해나가며 동일한 정보를 가진다고 간주할 수 있다고 찾은 영역을 의미한다.
  - 두번째 그림은 특정 텍스트를 `autos(자동차) 카테고리로 분류한 이유`를 설명한다.
    ![LIME2](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-8.png)
    + 우측 상단에 Not autos로 판단한 텍스트 및 autos로 판단한 텍스트 및 확률이 등장한다.
    + 하단에는 해당 단어들이 하이라이트 되어 가독성을 높혀준다.
  - 세번째 그림은 올리베티 이미지를 XAI한 결과이다.
    ![LIME3](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-9.png)
    + `분홍색` 영역은 해당 인물을 21번째 사람으로 분류한 조각이며, `파란색`은 2번째 사람, `노란색`은 도움이 되지 않는 영역이다.
  - 네번째 그림은 각 N번째 사람으로 분류한 근거 이미지 조각과 `34번째 사람의 일치율`을 확인하는 과정이다.
    ![LIME4](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-10.png)
  - 이처럼 LIME 기법은 데이터 하나에 초점을 맞추어 결정 경계를 분석하고 모델을 수정할 방향을 찾을 수 있게 도와준다.

---

* __기법5 - `SHAP`(Shapley Additive exPlanations)__   
  - 섀플리값과 피처 간 독립성을 활용하여 전체 성과를 창출하는데 각 피처가 얼마나 공헌했는지 파악하는 기법이다.
  - 위에서 언급한 피처 중요도의 단점 및 부분 의존성 플롯이 3차원까지의 관계만 표현할 수 있다는 한계를 극복할 수 있다.
  - 단, 계산 시간이 오래걸린다. 샘플 계산량을 줄이면 오차의 분산이 커진다. 더불어 새로운 아웃라이어 데이터에 취약하다.
  - 아래 그림은 보스턴 주택 가격 결정 요소와 관련하여 0번 주택의 가격에 영향을 미친 긍정, 부정의 요소를 찾아낸 결과이다.
  ![SHAP1](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-11.png)
  ![SHAP2](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-12.png)

---

* __기법6 - `필터 시각화`(Filter Visualization)__   
  - 이미지 딥러닝 계열의 은닉층에서 주로 사용하는 필터를 시각화하는 기법이다.
  - 아래 그림은 숫자 2와 7의 은닉층 필터를 시각화한 결과로 숫자 2의 꼬리획을 흐리게 해석하여 성능이 저하됨을 확인할 수 있다.
  ![필터 시각화](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-13.png)
  - 위와 같은 문제를 발견 시, 꼬리획 특징을 분리하는 필터를 추가하거나 데이터를 키워 모델의 분별력을 키우는 등의 조치가 가능할 것이다. 

---

* __기법7 - `계층별 타당성 전파`(LRP, Layer-wise Relevance Propagation)__   
  - 딥러닝 모델의 결과를 역추적하여 입력 이미지에 히트맵을 출력하는 기법이다.
  - LIME이나 SHAP이 민감도 분석 기법인데 반해, LRP는 타당성 전파 및 분해 기법을 활용한다.
  - 아래 그림은 MNIST 이미지의 LRP를 수행한 결과로 각 숫자의 주요 특징이 히트맵 표시되어 있음을 알 수 있다.
  ![LRP](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-14.png)
  

---

* __마무리__  
  그 외 유익한 점 및 흥미로웠던 점을 정리하며 리뷰를 마칠까 한다.

  + 위 7가지 기법을 종합적으로 엮어 8, 9장 `실전연습`에서 활용할 수 있다. 
    - 8장 : 아래와 같이 13번째 사용자는 수입이 적었음에도 신용등급과 나이 덕분에 대출이 승인되었음을 알 수 있다.
    ![신용대출](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-15.png)
    - 9장 : 그림과 같이 학습한 모델에 새로운 이미지를 입력한 결과 슬픈 사진으로 판단했다. LRP는 처진 눈, 아래로 뻗은 인중 등을 주시한다.
    ![슬픈사진](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-16.png)

  + XAI를 적용하여 개선할 AI에 대한 `선수 지식`을 튼튼히한다.
    - 의사결정트리 모델의 설명에 앞서 엔트로피의 개념을 명확히한다.
    - XGBoost의 기본원리부터 수식까지 핵심을 놓치지 않는 설명이 인상적이었다.
    ![XGBoost](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-4.png)

  + 수식의 전개를 `직접 숫자까지 넣어 이해시켜주는` 친절한 책은 처음 만난것 같다.
    ![엔트로피](https://theorydb.github.io/assets/img/review/2020-06-05-review-book-xai-2.png)
    위 그림은 엔트로피에 관한 수식 설명인데 보시다시피 그림 예제에 따른 숫자까지 대입해가며 설명하기에 쉽게 이해할 수 있었다.

  + 각 이론의 배경지식 및 연구성과에 대한 설명이 탄탄하며 관련 `레퍼런스`들이 각주에 친절히 안내되어 있어 참고 시 시간을 줄여준다.  

  + `전처리` 과정을 비중있게 다루는 편이며 저자의 경험과 스킬이 소개된다.
  
  + 여담으로 저자분은 다독가이신 듯 하다. "도개교", "환원적 관점"이라는 단어는 IT서적에서는 처음본 것 같다. 그만큼 책의 가독성, 전달력이 인상깊었다.
  
  > "제가 학생일 땐 돈이 없어서, 그러니까 기회비용이 커서 다양한 책을 구매해보지 못했습니다."

  TensorFlow KR 페이스북 그룹에서 돈이 충분하지 않은 연구자들을 위해 진행한 안재현 저자님의 이벤트 - [인공지능 연구자들을 위해 책을 드립니다!](https://www.facebook.com/groups/TensorFlowKR/permalink/1156872661320457/) - 글 중 일부이다.
  
  저자님의 따뜻한 마음씨가 감동이었고 특히 이벤트가 아니었다면 이런 멋진 책을 못보고 지나칠 뻔 했다. 보답하고픈 마음에 주저리 주저리 글은 길어졌는데 리뷰는 책의 진가에 비해 한참 모자른 것 같다. AI에 관심이 있는 분이라면 꼭 읽어보시길 추천한다.

* [책소개 - XAI 설명 가능한 인공지능, 인공지능을 해부하다](http://www.yes24.com/Product/Goods/89583774?scode=032&OzSrank=1)


